{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "# Import Annotation3D from matplotlib for 3d scatter plot\n",
    "from mpl_toolkits.mplot3d.proj3d import proj_transform\n",
    "\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.manifold import MDS\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT = os.path.join(\"images\", \"svg\")\n",
    "# https://github.com/linssen/country-flag-icons\n",
    "\n",
    "image_paths = [os.path.join(ROOT, nm) for nm in os.listdir(ROOT)]\n",
    "\n",
    "COUNTRIES_PATH = os.path.join(\"images\", \"png\", \"countries\")\n",
    "png_paths = [os.path.join(COUNTRIES_PATH, nm) for nm in os.listdir(COUNTRIES_PATH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"json/code2country.json\", \"r\") as f:\n",
    "    code2country = json.load(f)\n",
    "\n",
    "country2code = {v: k for k, v in code2country.items()}\n",
    "\n",
    "code2country"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDP and population for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open GDPpC.json\n",
    "with open(\"json/GDPpC.json\", \"r\") as f:\n",
    "    GDPpC = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Population.json\n",
    "with open(\"population.json\", \"r\") as f:\n",
    "    population = json.load(f)\n",
    "\n",
    "# Compare the keys of Population and values of code2country\n",
    "population_keys = set(population.keys())\n",
    "countries = set(code2country.keys())\n",
    "\n",
    "different_spellings_dict = {\n",
    "    \"Czech Republic\": \"Czechia\",\n",
    "    \"Ivory Coast\": \"Côte d'Ivoire\",\n",
    "    \"DR Congo\": \"Democratic Republic of Congo\",\n",
    "    \"Congo\": \"Republic of Congo\",\n",
    "    \"Turkey\": \"Türkiye\",\n",
    "}\n",
    "\n",
    "# Print difference\n",
    "print(sorted(population_keys - countries))\n",
    "print(sorted(countries - population_keys))\n",
    "\n",
    "# Save population json with only the countries in code2country, using the different spellings dict\n",
    "# new_population = {country2code[k] if k in country2code else country2code[different_spellings_dict[k]]:v for k, v in population.items() if k in country2code or k in different_spellings_dict}\n",
    "\n",
    "# Sort by code\n",
    "# new_population = {k: new_population[k] for k in sorted(new_population.keys())}\n",
    "# with open(\"population_new.json\", \"w\") as f:\n",
    "#     json.dump(new_population, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display flags in order of GDP\n",
    "\n",
    "# Get GDP by multiplying population by GDP per capita\n",
    "GDP = {k: population[k] * GDPpC[k] * 1e-6 for k in population.keys()}\n",
    "\n",
    "# Sort by GDP\n",
    "GDP = {k: GDP[k] for k in sorted(GDP.keys(), key=lambda x: GDP[x], reverse=True)}\n",
    "\n",
    "# Display flags in order of GDP\n",
    "for code, gdp in list(GDP.items())[:5]:\n",
    "    print(code2country[code], gdp)\n",
    "\n",
    "    # Plot the flag\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(Image.open(os.path.join(COUNTRIES_PATH, code + \".png\")))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_log = {k: np.log(v) for k, v in GDP.items()}\n",
    "GDP_from_0 = {k: v-min(GDP_log.values()) for k, v in GDP_log.items()}\n",
    "GDP_around_0 = {k: v-(np.mean(list(GDP_from_0.values()))*1.2) for k, v in GDP_from_0.items()}\n",
    "GDP_closer_around_0 = {k: v/(np.mean(list(GDP_from_0.values()))/30) for k, v in GDP_around_0.items()}\n",
    "GDP_sigmoid = {k: 1 / (1 + np.exp(-v)) for k, v in GDP_closer_around_0.items()}\n",
    "\n",
    "# Plot barchart of GDP\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.bar(range(len(GDP)), list(GDP_sigmoid.values()), align=\"center\")\n",
    "\n",
    "# Add flags to barchart\n",
    "for i, (code, gdp) in enumerate(GDP_sigmoid.items()):\n",
    "    im = Image.open(os.path.join(COUNTRIES_PATH, code + \".png\"))\n",
    "    im.thumbnail((50, 50), Image.ANTIALIAS)\n",
    "    imagebox = OffsetImage(im, zoom=0.2)\n",
    "    ab = AnnotationBbox(imagebox, (i, gdp), xybox=(0, 0), xycoords=\"data\", boxcoords=\"offset points\", pad=0.1)\n",
    "    plt.gca().add_artist(ab)\n",
    "\n",
    "plt.xticks(range(len(GDP)), list(GDP.keys()), rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Most stuff before malaysia is probably known\n",
    "# Turning point should probably be around Sri Lanka\n",
    "\n",
    "# Save json of GDP probabilities\n",
    "with open(\"json/GDP_probabilities.json\", \"w\") as f:\n",
    "    json.dump(GDP_sigmoid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EMA_new = alpha * latest_outcome + (1 - alpha) * EMA_previous\n",
    "\n",
    "Where:\n",
    "\n",
    "EMA_new is the updated exponential moving average.\n",
    "alpha is the discount factor, which determines how much weight is given to the latest outcome. It should be a value between 0 and 1.\n",
    "latest_outcome is the most recent outcome (e.g., 1 for success, 0 for failure).\n",
    "EMA_previous is the previous value of the exponential moving average.\n",
    "To get started, you need to decide on the value of the discount factor (alpha). A higher alpha will give more weight to the latest outcome, making the success rate more sensitive to recent changes. Conversely, a lower alpha will make the success rate more stable and less responsive to recent outcomes.\n",
    "\n",
    "Here's how you can use this formula to update the success rate in your quiz game:\n",
    "\n",
    "Initialize the success rate (EMA) to a reasonable starting value (e.g., 0.5 or 50%).\n",
    "For each new outcome (success or failure), update the EMA using the formula above.\n",
    "For example, let's say you set alpha to 0.2 (meaning you want to give 20% weight to the latest outcome). If your current EMA is 0.6 (60% success rate) and the latest outcome is a success (1), the updated EMA will be:\n",
    "\n",
    "EMA_new = 0.2 * 1 + (1 - 0.2) * 0.6\n",
    "EMA_new = 0.2 + 0.8 * 0.6\n",
    "EMA_new = 0.2 + 0.48\n",
    "EMA_new = 0.68\n",
    "\n",
    "So, the new success rate (EMA) is 0.68 or 68%.\n",
    "\n",
    "By continuing to update the EMA with new outcomes, you'll have a success rate that is weighted towards recent results while still considering past performance. Adjusting the value of alpha will allow you to control the sensitivity of the success rate to recent changes in performance.\"\"\"\n",
    "\n",
    "# Plot line graph of EMA starting at 0 and adding random new outcomes\n",
    "\n",
    "# Initialize EMA\n",
    "EMA = 0\n",
    "\n",
    "# Initialize alpha\n",
    "alpha = 0.3\n",
    "\n",
    "# Initialize list of EMA values\n",
    "EMA_values = []\n",
    "\n",
    "for i in range(100):\n",
    "    # Add EMA to list\n",
    "    EMA_values.append(EMA)\n",
    "\n",
    "    # Generate random outcome (0 or 1 with 80% probability of 1)\n",
    "    outcome = np.random.randint(0, 5)\n",
    "    if outcome > 0:\n",
    "        outcome = 1\n",
    "\n",
    "    # Update EMA\n",
    "    EMA = alpha * outcome + (1 - alpha) * EMA\n",
    "\n",
    "# Plot EMA values\n",
    "plt.plot(EMA_values)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVG 2 PNG Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cairosvg import svg2png\n",
    "\n",
    "# for path in image_paths:\n",
    "#     with open(path, \"r\") as f:\n",
    "#         content = f.read()\n",
    "#     with open(path.replace(\"svg\", \"png\"), \"w\") as f:\n",
    "#         svg2png(content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from svglib.svglib import svg2rlg\n",
    "# from reportlab.graphics import renderPM\n",
    "# import PIL\n",
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# for path in image_paths:\n",
    "#     content = svg2rlg(path)\n",
    "#     pil = renderPM.drawToPIL(content)\n",
    "#     plt.imshow(np.array(pil))\n",
    "#     pil.save(path.replace(\"svg\", \"png\"), \"PNG\")\n",
    "#     renderPM.drawToFile(content, path.replace(\"svg\", \"png\"), fmt='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INKSCAPE_PATH = os.path.join(\"C:\\\\\",\"Program Files\",\"Inkscape\",\"bin\",\"inkscape.exe\")\n",
    "\"\"\"https://inkscape.org/doc/inkscape-man.html\"\"\"\n",
    "\n",
    "def convert_svgs_to_png(image_paths):\n",
    "    for path in image_paths:\n",
    "        save_path = path.replace('svg', 'png')\n",
    "        command = f\"\"\" \"{INKSCAPE_PATH}\" --export-filename=\"{save_path}\" \"{path}\" \"\"\"\n",
    "        # print(command)\n",
    "        stream = os.popen(command)\n",
    "        # print(stream)\n",
    "    # plt.savefig(,pad_inches = 0)\n",
    "\n",
    "# Only kos.svg\n",
    "# convert_svgs_to_png([os.path.join(ROOT, \"kos.svg\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the color distributions from json file named \"color_distribs.json\"\n",
    "with open(\"color_distribs.json\", \"r\") as f:\n",
    "    color_distrs = json.load(f)\n",
    "\n",
    "# convert the inner keys back to tuples\n",
    "color_distrs = {k:{tuple(eval(kk)):vv for kk,vv in v.items()} for k,v in color_distrs.items()}\n",
    "color_distrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HSL(RGB, lookup=True):\n",
    "    \"\"\"Convert RGB color vector into HSL color space. Returns a 3-element vector, HSL, which contains the H, S, and L values, \n",
    "    which range from 0 to 360, 0 to 1.0, and 0 to 1.0, respectively.\"\"\"\n",
    "    if HSL_lookup and lookup:\n",
    "        return HSL_dict[tuple(RGB)]\n",
    "\n",
    "    # RGB values lie between 0 to 1.0\n",
    "    assert 0 <= RGB[0] <= 1.0 and 0 <= RGB[1] <= 1.0 and 0 <= RGB[2] <= 1.0\n",
    "\n",
    "    # Conversion\n",
    "    Cmax = np.max(RGB)\n",
    "    Cmin = np.min(RGB)\n",
    "    delta = Cmax - Cmin\n",
    "\n",
    "    # Hue\n",
    "    if delta == 0:\n",
    "        H = 0\n",
    "    elif Cmax == RGB[0]:\n",
    "        H = 60 * (((RGB[1] - RGB[2]) / delta) % 6)\n",
    "    elif Cmax == RGB[1]:\n",
    "        H = 60 * (((RGB[2] - RGB[0]) / delta) + 2)\n",
    "    elif Cmax == RGB[2]:\n",
    "        H = 60 * (((RGB[0] - RGB[1]) / delta) + 4)\n",
    "\n",
    "    # Lightness\n",
    "    L = (Cmax + Cmin) / 2\n",
    "\n",
    "    # Saturation\n",
    "    if delta == 0:\n",
    "        S = 0\n",
    "    else:\n",
    "        S = delta / (1 - np.abs(2 * L - 1))\n",
    "\n",
    "    return np.array([H, S, L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dictionary for looking up Lab color from RGB color for each color in the color distributions\n",
    "HSL_lookup = False\n",
    "HSL_dict = {} # {RGB: HSL}\n",
    "for code, colors in color_distrs.items():\n",
    "    for color in colors:\n",
    "        if color not in HSL_dict:\n",
    "            HSL_dict[color] = RGB2HSL(np.array(color))\n",
    "\n",
    "HSL_lookup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSL_dist(color1, color2, weights=[5,1,1]):\n",
    "    \"\"\"Computes a custom distance between two colors in HSL space\"\"\"\n",
    "    color1, color2 = RGB2HSL(color1), RGB2HSL(color2)\n",
    "\n",
    "    H_dist = min(abs(color1[0]-color2[0]), 360-abs(color1[0]-color2[0]))/180\n",
    "    S_dist = abs(color1[1]-color2[1])\n",
    "    L_dist = abs(color1[2]-color2[2])\n",
    "    return np.sqrt((weights[0]*H_dist)**2 + (weights[1]*S_dist)**2 + (weights[2]*L_dist)**2)\n",
    "\n",
    "def HSL_similarity(color1, color2, weights=[5,1,1]):\n",
    "    \"\"\"Computes a custom similarity between two colors in HSL space\"\"\"\n",
    "    max_dist = np.sqrt((weights[0])**2 + (weights[1])**2 + (weights[2])**2)\n",
    "    return 1 - HSL_dist(color1, color2, weights) / max_dist\n",
    "\n",
    "def get_nearest_color(color, color_distr, dist_fn=HSL_dist, factor=1):\n",
    "    \"\"\"Get the color in color_distr that has the lowest distance to color. \n",
    "    Can set factor to -1 to get the color with the highest distance, or similarity if dist_fn is a similarity function.\"\"\"\n",
    "    min_distance = np.inf\n",
    "    for color2 in color_distr.keys():\n",
    "        color2 = np.array(color2)\n",
    "        distance = dist_fn(color, color2) * factor\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_color = color2\n",
    "    return nearest_color, min_distance\n",
    "\n",
    "def calc_color_distrib_similarity(color_distr1, color_distr2, sim_fn=HSL_similarity):\n",
    "    \"\"\"Calculate the similarity between two color distributions uniformly weighted\"\"\"\n",
    "    similarity = 0.\n",
    "    color_ctr = 0\n",
    "    for color1, percent1 in color_distr1.items():\n",
    "        color1 = np.array(color1)\n",
    "        color2, neg_sim = get_nearest_color(color1, color_distr2, sim_fn, factor=-1)\n",
    "\n",
    "        # Do a little hardcoded hack to ignore white unless it's both white, and same with black\n",
    "        # This is especially important when using HSL because we emphasize the H\n",
    "        from_white, to_white = np.mean(color1) >= 0.97, np.mean(color2) >= 0.97\n",
    "        from_black, to_black = np.mean(color1) <= 0.03, np.mean(color2) <= 0.03\n",
    "        if (from_white or from_black) and not (to_white or to_black):\n",
    "            color_ctr += 0.1\n",
    "            continue\n",
    "        elif (to_white or to_black) and not (from_white or from_black):\n",
    "            color_ctr += 1\n",
    "            continue\n",
    "\n",
    "        sim = -neg_sim\n",
    "        similarity += sim\n",
    "        color_ctr += 1\n",
    "\n",
    "    return similarity / max(1,color_ctr)\n",
    "\n",
    "def calc_color_distrib_similarity_matrix_symmetrical(color_distrs, sim_fn=HSL_similarity):\n",
    "    \"\"\"Calculate the similarities between all pairs of color distributions as NxN matrix\"\"\"\n",
    "    countries = list(color_distrs.keys())\n",
    "    N = len(countries)\n",
    "    similarity_matrix = np.zeros((N,N))\n",
    "    for i in tqdm(range(N)):\n",
    "        for j in range(N):\n",
    "            if i > j:\n",
    "                similarity_matrix[i,j] = similarity_matrix[j,i]\n",
    "                continue\n",
    "\n",
    "            similarity_matrix[i,j] = np.round(min(\n",
    "                calc_color_distrib_similarity(color_distrs[countries[i]], color_distrs[countries[j]], sim_fn=sim_fn),\n",
    "                calc_color_distrib_similarity(color_distrs[countries[j]], color_distrs[countries[i]], sim_fn=sim_fn)\n",
    "            ), 2)\n",
    "    similarity_matrix = similarity_matrix / similarity_matrix.max()\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dist_matrix = 1 - calc_color_distrib_similarity_matrix_symmetrical(color_distrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the similarity matrix\n",
    "# plt.figure(figsize=(20,20))\n",
    "plt.imshow(color_dist_matrix)\n",
    "print(color_dist_matrix.min(), color_dist_matrix.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save color_dist_matrix to json file\n",
    "with open(\"color_dist_matrix.json\", \"w\") as f:\n",
    "    json.dump(color_dist_matrix.tolist(), f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detect(img):\n",
    "    \"\"\"Simple edge detector by convolving with a 3x3 kernel. Give NCHW or CHW tensor, return N1HW or 1HW array\"\"\"\n",
    "    # horizontal edge detector\n",
    "    hkernel = np.array([[1,1,1],[0,0,0],[-1,-1,-1]]).astype(np.float32)\n",
    "    # vertical edge detector\n",
    "    vkernel = np.array([[1,0,-1],[1,0,-1],[1,0,-1]]).astype(np.float32)\n",
    "    # diagonal edge detector\n",
    "    d1kernel = np.array([[1,0,-1],[0,0,0],[-1,0,1]]).astype(np.float32)\n",
    "    # diagonal edge detector\n",
    "    d2kernel = np.array([[-1,0,1],[0,0,0],[1,0,-1]]).astype(np.float32)\n",
    "\n",
    "    img = np.array(img) # NCHW or CHW\n",
    "    if len(img.shape) == 3:\n",
    "        img = img[None,:,:,:] # CHW -> NCHW\n",
    "    img = img.mean(axis=1, keepdims=True) # NCHW -> N1HW\n",
    "    img = img.astype(np.float32)\n",
    "    img = torch.tensor(img)\n",
    "\n",
    "    img = torch.nn.functional.pad(img, (1,1,1,1), mode=\"replicate\")\n",
    "    h_edges = torch.nn.functional.conv2d(img, torch.tensor(hkernel).unsqueeze(0).unsqueeze(0))\n",
    "    v_edges = torch.nn.functional.conv2d(img, torch.tensor(vkernel).unsqueeze(0).unsqueeze(0))\n",
    "    d1_edges = torch.nn.functional.conv2d(img, torch.tensor(d1kernel).unsqueeze(0).unsqueeze(0))\n",
    "    d2_edges = torch.nn.functional.conv2d(img, torch.tensor(d2kernel).unsqueeze(0).unsqueeze(0))\n",
    "    img = h_edges**2 + v_edges**2 + d1_edges**2 + d2_edges**2\n",
    "    img[img>0.0001] = 1\n",
    "    img = img.squeeze(0) # 11HW -> 1HW\n",
    "\n",
    "    return img.numpy()\n",
    "\n",
    "# Show edge detection\n",
    "for path in png_paths[:3]:\n",
    "    img = Image.open(path)\n",
    "    img = np.array(img).transpose(2,0,1) # HWC -> CHW\n",
    "    # img = img.resize((128,128))\n",
    "    img = edge_detect(img)\n",
    "    plt.imshow(img.squeeze(0), cmap=\"gray\")\n",
    "    plt.axis(\"Off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = torchvision.transforms.Resize((66,66))\n",
    "\n",
    "countries = [code2country[path.split(\"\\\\\")[-1].split(\".\")[0]] for path in png_paths]\n",
    "\n",
    "\"\"\"Create NxN matrix of countries where N is the number of countries in the dataset.\n",
    "The value at (i,j) is the MSE between the two countries' flags.\"\"\"\n",
    "\n",
    "\n",
    "def get_mse(img1, img2):\n",
    "    return np.square(img1 - img2).mean()\n",
    "\n",
    "def get_mse_matrix(png_paths):\n",
    "    matrix = np.zeros((len(png_paths), len(png_paths)))\n",
    "    for i in tqdm(range(len(png_paths))):\n",
    "        img1 = np.array(Image.open(png_paths[i]))[:,:,:3]\n",
    "        pil1 = Image.fromarray(img1)\n",
    "        resized1 = resize(pil1)\n",
    "        resized1 = np.array(resized1)\n",
    "        for j in range(len(png_paths)):\n",
    "            if i <= j:\n",
    "                continue\n",
    "            img2 = np.array(Image.open(png_paths[j]))[:,:,:3]\n",
    "            pil2 = Image.fromarray(img2)\n",
    "            resized2 = resize(pil2)\n",
    "            resized2 = np.array(resized2)\n",
    "\n",
    "            matrix[i,j] = get_mse(resized1, resized2)\n",
    "    return matrix\n",
    "\n",
    "mse_matrix = get_mse_matrix(png_paths[:20])\n",
    "\n",
    "plt.imshow(mse_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to see distance between flags:\n",
    "- MSE\n",
    "- MSE of flipped image\n",
    "- MSE of colors permuted (no idea how I'd implement this)\n",
    "- MSE of edges\n",
    "- MSE of blurred edges (or even blurred images)\n",
    "- distance between color distributions (maybe just the sum of R, G and B, or maybe cluster most common colors and see how much there is of those)\n",
    "- make encodings (potentially with distortions) and get distance between them\n",
    "\n",
    "check why edges mse of iceland and norway is so high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2HSLvectorized(RGB):\n",
    "    \"\"\"Converts an Nx3 matrix to an Nx3 matrix where each pixel is in HSL space, using matrix multiplication and numpy.\"\"\"\n",
    "    RGB = RGB.astype(np.float32)\n",
    "    R = RGB[:,0]\n",
    "    G = RGB[:,1]\n",
    "    B = RGB[:,2]\n",
    "    Cmax = RGB.max(axis=1)\n",
    "    Cmin = RGB.min(axis=1)\n",
    "    # Make sure delta is not 0\n",
    "    delta = np.clip(Cmax - Cmin, 1e-8, None)\n",
    "    L = (Cmax + Cmin) / 2\n",
    "    # Make sure denominator is not 0\n",
    "    denominator = np.clip(1 - np.abs(2*L - 1), 1e-8, None)\n",
    "    S = delta / denominator\n",
    "    H = np.zeros_like(L)\n",
    "    H[Cmax == R] = 60 * (((G-B)/delta) % 6)[Cmax == R]\n",
    "    H[Cmax == G] = 60 * (((B-R)/delta) + 2)[Cmax == G]\n",
    "    H[Cmax == B] = 60 * (((R-G)/delta) + 4)[Cmax == B]\n",
    "    HSL = np.stack([H,S,L], axis=1)\n",
    "    return HSL\n",
    "\n",
    "def RGBmatrix2HSLmatrix(RGBmatrix):\n",
    "    \"\"\"Converts an Nx3xHxW matrix to an Nx3xHxW matrix where each pixel is in HSL space, using RGB2HSLvectorized and reshaping when necessary.\"\"\"\n",
    "    N, _, H, W = RGBmatrix.shape\n",
    "    RGBmatrix = RGBmatrix.transpose(0,2,3,1)\n",
    "    RGBmatrix = RGBmatrix.reshape(-1,3)\n",
    "    HSLmatrix = RGB2HSLvectorized(RGBmatrix)\n",
    "    HSLmatrix = HSLmatrix.reshape(N,H,W,3)\n",
    "    HSLmatrix = HSLmatrix.transpose(0,3,1,2)\n",
    "    return HSLmatrix\n",
    "\n",
    "def get_mse_matrix_vectorized(png_paths, edges=False, size=66, HSL=False, hflip=False, vflip=False, rot90=False, rot270=False):\n",
    "    \"\"\"construct two matrices containing all flags, one for each country.\n",
    "    Then subtract the two matrices and square the result. The mean of this matrix\n",
    "    is the MSE between the two countries' flags.\"\"\"\n",
    "    # Flag matrix base (N, 3, 66, 66), where N is the number of countries\n",
    "    flag_matrix = np.zeros((len(png_paths), 3, size, size))\n",
    "    for i in tqdm(range(len(png_paths))):\n",
    "        img = np.array(Image.open(png_paths[i]))[:,:,:3] # (H, W, 3)\n",
    "        pil = Image.fromarray(img)\n",
    "        resized = pil.resize((size,size))\n",
    "        resized = np.array(resized)\n",
    "        flag_matrix[i] = resized.transpose(2,0,1)\n",
    "\n",
    "    if flag_matrix.max() > 1:\n",
    "        flag_matrix = flag_matrix / 255\n",
    "\n",
    "    if edges:\n",
    "        flag_matrix = edge_detect(flag_matrix)\n",
    "    elif HSL:\n",
    "        flag_matrix = RGBmatrix2HSLmatrix(flag_matrix)\n",
    "\n",
    "    # Flag matrix 1 (NxN, C, 66, 66) where the first N 3D matrices are the same, the second N 3D matrices are the same, etc.\n",
    "    flag_matrix1 = np.repeat(flag_matrix, len(png_paths), axis=0)\n",
    "    # Flag matrix 2 (NxN, C, 66, 66) where the first N 3D matrices are all different, the second N 3D matrices are all different, etc.\n",
    "    flag_matrix2 = np.tile(flag_matrix, (len(png_paths), 1, 1, 1))\n",
    "    if hflip:\n",
    "        flag_matrix2 = flag_matrix2[:,:,::-1,:]\n",
    "    if vflip:\n",
    "        flag_matrix2 = flag_matrix2[:,:,:,::-1]\n",
    "    if rot90:\n",
    "        flag_matrix2 = np.rot90(flag_matrix2, axes=(2,3))\n",
    "    if rot270:\n",
    "        flag_matrix2 = np.rot90(flag_matrix2, axes=(3,2))\n",
    "\n",
    "    # Subtract the two matrices and square the result (NxN, C, 66, 66)\n",
    "    if HSL:\n",
    "        # Take into account that H is a circular variable\n",
    "        diff_matrix = np.abs(flag_matrix1 - flag_matrix2)\n",
    "        diff_matrix[:,0] = np.minimum(diff_matrix[:,0], 360 - diff_matrix[:,0]) / 180 # divide by 180 to normalize\n",
    "        diff_matrix = diff_matrix**2\n",
    "    else:\n",
    "        diff_matrix = (flag_matrix1 - flag_matrix2)**2\n",
    "\n",
    "    # Take the mean of the matrix (NxN)\n",
    "    mse_matrix = diff_matrix.mean(axis=1).mean(axis=1).mean(axis=1)\n",
    "    # Reshape to (N, N)\n",
    "    mse_matrix = mse_matrix.reshape(len(png_paths), len(png_paths))\n",
    "    return mse_matrix / mse_matrix.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import colorsys to convert RGB to HSL\n",
    "import colorsys\n",
    "\n",
    "# Test RGB2HSLvectorized using RGB float values\n",
    "RGB = np.random.rand(100,3)\n",
    "HSL_v = RGB2HSLvectorized(RGB)\n",
    "HSL = np.array([RGB2HSL(rgb, False) for rgb in RGB])\n",
    "HSL2 = np.array([colorsys.rgb_to_hls(*rgb) for rgb in RGB])\n",
    "HSL2[:,0] = HSL2[:,0] * 360\n",
    "# Switch axis 1 and 2 in HSL2\n",
    "HSL2 = np.stack([HSL2[:,0], HSL2[:,2], HSL2[:,1]], axis=1)\n",
    "\n",
    "np.allclose(HSL_v, HSL2)\n",
    "\n",
    "# print(HSL2[:,0].max())\n",
    "# print(HSL[:,0].max())\n",
    "# print(HSL_v[:,0].max())\n",
    "# print()\n",
    "# print(HSL2[:,1].max())\n",
    "# print(HSL[:,1].max())\n",
    "# print(HSL_v[:,1].max())\n",
    "# print()\n",
    "# print(HSL2[:,2].max())\n",
    "# print(HSL[:,2].max())\n",
    "# print(HSL_v[:,2].max())\n",
    "# print()\n",
    "# print(HSL2[:,0].min())\n",
    "# print(HSL[:,0].min())\n",
    "# print(HSL_v[:,0].min())\n",
    "# print()\n",
    "# print(HSL2[:,1].min())\n",
    "# print(HSL[:,1].min())\n",
    "# print(HSL_v[:,1].min())\n",
    "# print()\n",
    "# print(HSL2[:,2].min())\n",
    "# print(HSL[:,2].min())\n",
    "# print(HSL_v[:,2].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_matrix = get_mse_matrix_vectorized(png_paths[:], HSL=False)\n",
    "\n",
    "# Plot and show range\n",
    "plt.imshow(mse_matrix)\n",
    "\n",
    "# Get the range of MSE values\n",
    "print(mse_matrix.min(), mse_matrix.max())\n",
    "\n",
    "# Save the matrix as json\n",
    "with open(\"flag_mse_matrix.json\", \"w\") as f:\n",
    "    json.dump(mse_matrix.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_matrix_hflip = get_mse_matrix_vectorized(png_paths[:], hflip=True)\n",
    "mse_matrix_vflip = get_mse_matrix_vectorized(png_paths[:], vflip=True)\n",
    "mse_matrix_rot90 = get_mse_matrix_vectorized(png_paths[:], rot90=True)\n",
    "mse_matrix_rot270 = get_mse_matrix_vectorized(png_paths[:], rot270=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the minimum of the 5 matrices to get the final matrix\n",
    "mse_matrix_transforms = np.minimum(\n",
    "    mse_matrix, np.minimum(\n",
    "    mse_matrix_hflip**(1/2), np.minimum(\n",
    "    mse_matrix_vflip**(1/2), np.minimum(\n",
    "    mse_matrix_rot90**(1/3), \n",
    "    mse_matrix_rot270**(1/3)\n",
    "))))\n",
    "\n",
    "mse_matrix_flips = np.minimum(\n",
    "    mse_matrix, np.minimum(\n",
    "    mse_matrix_hflip,\n",
    "    mse_matrix_vflip\n",
    "))\n",
    "\n",
    "mse_matrix_rotations = np.minimum(\n",
    "    mse_matrix, np.minimum(\n",
    "    mse_matrix_rot90,\n",
    "    mse_matrix_rot270\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"flag_mse_matrix_flips.json\", \"w\") as f:\n",
    "    json.dump(mse_matrix_flips.tolist(), f)\n",
    "\n",
    "with open(\"flag_mse_matrix_rotations.json\", \"w\") as f:\n",
    "    json.dump(mse_matrix_rotations.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_matrix_edges = get_mse_matrix_vectorized(png_paths[:], edges=True, size=33)\n",
    "\n",
    "plt.imshow(mse_matrix_edges)\n",
    "\n",
    "# Get the range of MSE values\n",
    "print(mse_matrix_edges.min(), mse_matrix_edges.max())\n",
    "\n",
    "# Save the matrix as json\n",
    "with open(\"flag_edges_mse_matrix.json\", \"w\") as f:\n",
    "    json.dump(mse_matrix_edges.tolist(), f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SANITY CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random example of a pair of flags in a row with its MSE\n",
    "i = np.random.randint(len(png_paths))\n",
    "j = np.random.randint(len(png_paths))\n",
    "\n",
    "i = list(code2country.values()).index(\"norway\")\n",
    "j = list(code2country.values()).index(\"iceland\")\n",
    "\n",
    "# get pair of flags with lowest MSE\n",
    "# i,j = np.unravel_index(np.argmin(mse_matrix_edges), mse_matrix_edges.shape)\n",
    "\n",
    "resize = torchvision.transforms.Resize((33,33))\n",
    "\n",
    "img1 = np.array(Image.open(png_paths[i]))[:,:,:3]\n",
    "pil1 = Image.fromarray(img1)\n",
    "resized1 = resize(pil1)\n",
    "resized1 = np.array(resized1)\n",
    "img2 = np.array(Image.open(png_paths[j]))[:,:,:3]\n",
    "pil2 = Image.fromarray(img2)\n",
    "resized2 = resize(pil2)\n",
    "resized2 = np.array(resized2)\n",
    "\n",
    "# Do edge detection\n",
    "edges = True\n",
    "if edges:\n",
    "    resized1 = edge_detect(resized1.transpose(2,0,1)).squeeze(0)\n",
    "    resized2 = edge_detect(resized2.transpose(2,0,1)).squeeze(0)\n",
    "\n",
    "    # # Blur the edges using PIL\n",
    "    # resized1 = Image.fromarray((resized1*255).astype(np.uint8))\n",
    "    # resized1 = resized1.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "    # resized2 = Image.fromarray((resized2*255).astype(np.uint8))\n",
    "    # resized2 = resized2.filter(ImageFilter.GaussianBlur(radius=5))\n",
    "\n",
    "    # Convert back to numpy array\n",
    "    resized1 = np.array(resized1)[None,:,:]\n",
    "    resized2 = np.array(resized2)[None,:,:]\n",
    "\n",
    "se_img = np.square(resized1 - resized2)\n",
    "if edges:\n",
    "    se_img = se_img.squeeze(0)\n",
    "else:\n",
    "    se_img = se_img.mean(axis=2)\n",
    "\n",
    "mse = se_img.mean()\n",
    "if edges:\n",
    "    print(mse, mse_matrix_edges[i,j])\n",
    "\n",
    "else:\n",
    "    print(mse, mse_matrix[i,j])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(resized1.squeeze(0))\n",
    "plt.title(list(code2country.values())[i])\n",
    "plt.axis(\"Off\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(resized2.squeeze(0))\n",
    "plt.title(list(code2country.values())[j])\n",
    "plt.axis(\"Off\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(se_img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.axis(\"Off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_pairs(matrix, amount=5):\n",
    "    countries = list(code2country.values())\n",
    "\n",
    "    # Get list of pairs of countries sorted by MSE\n",
    "    pairs = []\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(len(matrix)):\n",
    "            if i <= j:\n",
    "                continue\n",
    "            pairs.append((countries[i], countries[j], matrix[i,j]))\n",
    "\n",
    "    pairs = sorted(pairs, key=lambda x: x[2])\n",
    "\n",
    "    # Display flags of countries with lowest MSE\n",
    "    for pair in pairs[:amount]:\n",
    "        img1 = np.array(Image.open(png_paths[countries.index(pair[0])]))[:,:,:3]\n",
    "        img2 = np.array(Image.open(png_paths[countries.index(pair[1])]))[:,:,:3]\n",
    "        pil1 = Image.fromarray(img1)\n",
    "        pil2 = Image.fromarray(img2)\n",
    "        resized1 = resize(pil1)\n",
    "        resized2 = resize(pil2)\n",
    "        resized1 = np.array(resized1)\n",
    "        resized2 = np.array(resized2)\n",
    "        # Plot flags in one row, with country as title, MSE in the middle\n",
    "        fig, ax = plt.subplots(1,2)\n",
    "        ax[0].imshow(resized1)\n",
    "        ax[0].set_title(pair[0])\n",
    "        ax[0].axis(\"Off\")\n",
    "        ax[1].imshow(resized2)\n",
    "        ax[1].set_title(pair[1])\n",
    "        ax[1].axis(\"Off\")\n",
    "        plt.suptitle(f\"MSE: {pair[2]:.4f}\")\n",
    "        plt.show()\n",
    "\n",
    "display_top_pairs(mse_matrix_rotations, amount=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_pairs(color_dist_matrix, amount=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise distances between flags are stored in a matrix called 'mse_matrix'\n",
    "# mse_matrix[i, j] contains the distance between flag i and flag j\n",
    "\n",
    "def get_2d_coordinates(distances):\n",
    "    # Create an MDS object with the desired number of dimensions\n",
    "    n_dimensions = 2  # Set the desired number of dimensions (in this case, 2)\n",
    "    mds = MDS(n_components=n_dimensions)\n",
    "\n",
    "    # Perform dimensionality reduction\n",
    "    coordinates = mds.fit_transform(distances)\n",
    "\n",
    "    # The 'coordinates' variable now contains the 2D coordinates of the flags\n",
    "\n",
    "    # You can access the x and y coordinates separately\n",
    "    x = coordinates[:, 0]\n",
    "    y = coordinates[:, 1]\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flags_2d(x, y):\n",
    "    # Plot the points in 2D space showing a small flag as the glyph\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    ax.scatter(x, y)\n",
    "\n",
    "    # Iterate over each point and plot the image as a marker\n",
    "    for xi, yi, image_path in zip(x, y, png_paths):\n",
    "        # Load the image file\n",
    "        img = Image.open(image_path)\n",
    "        img = img.resize((100, 100))\n",
    "        img = np.array(img)\n",
    "        # Zero pad the image to give it a one-pixel black border\n",
    "        img = np.pad(img, ((10, 10), (10, 10), (0, 0)), constant_values=0)\n",
    "\n",
    "        # Create an AnnotationBbox with the image as the marker\n",
    "        imagebox = OffsetImage(img, zoom=0.25)\n",
    "        ab = AnnotationBbox(imagebox, (xi, yi), frameon=False)\n",
    "        \n",
    "        # Add the AnnotationBbox to the axes\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    # Set the x and y limits of the plot\n",
    "    ax.set_xlim(min(x), max(x))\n",
    "    ax.set_ylim(min(y), max(y))\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_2d_coordinates(mse_matrix_transforms)\n",
    "plot_flags_2d(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_2d_coordinates(mse_matrix_edges)\n",
    "plot_flags_2d(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv_color_matrix = color_matrix.max() - color_matrix\n",
    "x, y = get_2d_coordinates(color_dist_matrix)\n",
    "plot_flags_2d(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_top_pairs(mse_matrix_edges + mse_matrix + color_dist_matrix, amount=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_2d_coordinates(mse_matrix_edges + mse_matrix/2 + color_dist_matrix)\n",
    "plot_flags_2d(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if there's correlation between flag distance and distance between countries\n",
    "\n",
    "Make slider for importance of each distance type and whilst adjusting it have the flags change position in real time (probably have to use a perceptron of some kind so be able to get those position (parameter) updates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b74cd7db1eb9f8499da7dbef20678a005a07ab79df7dd49707a224686fb33242"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
